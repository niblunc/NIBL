{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import argparse\n",
    "import os\n",
    "import subprocess\n",
    "import datetime\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parser():\n",
    "    global parser\n",
    "    global arglist\n",
    "    global args\n",
    "    parser=argparse.ArgumentParser(description='preprocessing')\n",
    "    #parser.add_argument('-task',dest='TASK', default=False, help='which task are we running on?')\n",
    "    parser.add_argument('-basedir',dest='BASEDIR',\n",
    "                        default=False, help='enter base directory path(should hold directories BIDS/ and derivatives/ )')\n",
    "    parser.add_argument('-moco',dest='MOCO',\n",
    "                        action=\"store_true\", help='this is using fsl_motion_outliers to preform motion correction and generate a confounds.txt as well as DVARS')\n",
    "    parser.add_argument('-bet',dest='STRIP',action='store_true',\n",
    "                        default=False, help='bet via fsl using defaults for functional images')\n",
    "    parser.add_argument('-ses',dest='SES',\n",
    "                        default=False, help='have multiple sessions?')\n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    arglist={}\n",
    "    for a in args._get_kwargs():\n",
    "        arglist[a[0]]=a[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_files():\n",
    "    global datestamp\n",
    "    global outhtml\n",
    "    global out_bad_bold_list\n",
    "    global outfile\n",
    "\n",
    "    datestamp=datetime.datetime.now().strftime(\"%Y-%m-%d-%H_%M_%S\")\n",
    "\n",
    "    if arglist[\"SES\"] == False:\n",
    "        outhtml = os.path.join(derivatives_dir,'bold_motion_QA_%s.html'%(datestamp))\n",
    "        out_bad_bold_list = os.path.join(derivatives_dir,'TEST_%s.txt'%(datestamp))\n",
    "    else:\n",
    "        outhtml = os.path.join(derivatives_dir,'%s_bold_motion_QA_%s.html'%(arglist[\"SES\"],datestamp))\n",
    "        out_bad_bold_list = os.path.join(derivatives_dir,'%s_TEST_%s.txt'%(arglist[\"SES\"], datestamp))\n",
    "    if arglist[\"MOCO\"] != False:\n",
    "        outfile = open(outhtml, 'a')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set_paths(sub) method assigns variables for our directory paths.\n",
    "[input (BIDS), output(anat, func, motion_assesment)]\n",
    "It takes the subject ID as an argument, and **it is called from get_subjects()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_paths(sub):\n",
    "    global func_output_path\n",
    "    global anat_output_path\n",
    "    global func_input_path\n",
    "    global motion_assessment_path\n",
    "\n",
    "    if arglist[\"SES\"] == False:\n",
    "        out_dir = os.path.join(derivatives_dir, sub)\n",
    "        func_input_path=os.path.join(input_dir,sub,\"fmriprep\", sub, \"func\")\n",
    "    else:\n",
    "        out_dir = os.path.join(derivatives_dir, sub, arglist[\"SES\"])\n",
    "        func_input_path=os.path.join(input_dir,sub,arglist[\"SES\"], \"fmriprep\", sub,arglist[\"SES\"], \"func\")\n",
    "    \n",
    "    \n",
    "    anat_output_path=os.path.join(out_dir, 'anat')\n",
    "    func_output_path=os.path.join(out_dir,'func')\n",
    "    motion_assessment_path=os.path.join(out_dir,'func','motion_assessment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The get_subjects() method gets an input directory, the BIDS path, we ask for the \"top level\" BIDS directory, where the subjects are listed, ~/STUDYNAME. For the output directory we ask for you to provide the location where you would like your derivatives directory to be, or the path to its location, however do not include the derivatives directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjects():\n",
    "    # Get subjects from input directory\n",
    "    sub_dir=glob.glob(os.path.join(input_dir, 'sub*'))\n",
    "    for path in sub_dir:\n",
    "        sub = path.split(\"/\")[-1]\n",
    "        subjects.append(sub)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skull_strip(sub):\n",
    "    print(\">>>>----------------> starting bet on \", sub )\n",
    "    try:\n",
    "        for nifti in glob.glob(os.path.join(func_input_path, '*bold_space-MNI152NLin2009cAsym_preproc.nii*')):\n",
    "            # make our variables\n",
    "            filename = nifti.split(\"/\")[-1].split(\".\")[0]\n",
    "            print(\"FILENAME \", filename)\n",
    "            bet_name=filename+'_brain'\n",
    "            # check if data exists already\n",
    "            bet_output = os.path.join(func_output_path, bet_name)\n",
    "            if os.path.exists(bet_output + '.nii'):\n",
    "                print(bet_output + ' exists, skipping \\n')\n",
    "            else:\n",
    "                print(\"Running bet on \", nifti)\n",
    "                ### ***********ADD IN PARSER FOR THE PARAMETER VALUE \n",
    "                bet_cmd=(\"bet %s %s -F -m -f 0.63\"%(nifti, bet_output))\n",
    "                print(\">>>-----> BET COMMAND:\", bet_cmd)\n",
    "                shutil.copy(nifti, func_output_path)\n",
    "                os.system(bet_cmd)\n",
    "    except FileNotFoundError:\n",
    "        print(\"BAD FILE PASSING\")\n",
    "        outfile = os.path.join(derivatives_dir, 'empty_subjects_betstrip.txt')\n",
    "        with open(outfile, 'a') as f:\n",
    "            f.write(\"Empty: %s \\n \"%(sub))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_check(sub):\n",
    "    print(\"---------> Starting motion correction on \", sub)\n",
    "    try:\n",
    "# iterate over nifti file\n",
    "        for nifti in glob.glob(os.path.join(func_output_path, '*brain.nii.gz')):\n",
    "            filename=nifti.split('.')[0]\n",
    "            file = filename.split(\"/\")[-1]\n",
    "            if \"run\" in file:\n",
    "                run_id = file.split(\"_\")[2]\n",
    "            elif \"task\" in file:\n",
    "                run_id = file.split(\"_\")[2]\n",
    "            else:\n",
    "                run_id = \"rest\"\n",
    "            print(\"RUN ID >>>>>>>>>--------> \", run_id)\n",
    "            # set comparison param\n",
    "            nvols_cmd=\"fslnvols \" + nifti\n",
    "            volume = subprocess.check_output(nvols_cmd, shell=True, encoding=\"utf-8\")\n",
    "            volume = volume.strip()\n",
    "            comparator = int(volume) *.25\n",
    "            ## RUN 'fsl_motion_outliers' TO RETRIEVE MOTION CORRECTION ANALYSIS\n",
    "            outlier_cmd = \"fsl_motion_outliers -i %s  -o %s/%s_confound.txt  --fd --thresh=0.9 -p %s/%s_fd_plot -v > %s/%s_outlier_output.txt\"%(filename, motion_assessment_path, file, motion_assessment_path,run_id, motion_assessment_path, file)\n",
    "            print(\">>>>>>>>>-------->  RUNNING FSL MOTION OUTLIERS \")\n",
    "            print(\"COMMAND NVOLS: \", nvols_cmd)\n",
    "            print(\"OUTLIER CMD: \", outlier_cmd)\n",
    "            os.system(outlier_cmd)\n",
    "        ## EXAMINE OUTLIER FILE AND GRAB RELEVANT DATA \n",
    "            outlier_file=\"%s/%s_outlier_output.txt\"%(motion_assessment_path, file)\n",
    "            with open(outlier_file, 'r') as f:\n",
    "                lines=f.readlines()\n",
    "                statsA = lines[1].strip(\"\\n\") #maskmean\n",
    "                statsB = lines[3].strip(\"\\n\") #metric range\n",
    "                statsC = lines[4].strip(\"\\n\") #outliers found\n",
    "                if int(statsC.split(\" \")[1])  > 0:\n",
    "                    statsD = lines[6].strip(\"\\n\") #spikes found\n",
    "                else:\n",
    "                    statsD = \"\\n\"\n",
    "            f.close()\n",
    "        ## GRAB MOTION CORRECTION PLOT AND WRITE PLOT & INFO TO HTML\n",
    "            plotz=os.path.join(motion_assessment_path, run_id+'_fd_plot.png')\n",
    "            FILEINFO=\"\"\"<p><font size=7> <b>{CURR_FILENAME} </b></font><br>\"\"\"\n",
    "            CURR_FILEINFO = FILEINFO.format(CURR_FILENAME=file)\n",
    "            outfile.write(CURR_FILEINFO)\n",
    "            INFO=\"\"\"<p><font size=6>{A} <br><b>{B}<b><br>{C}<br><b>{D}</b><br><br>\"\"\"\n",
    "            CURR_INFO= INFO.format(A=statsA, B=statsB, C=statsC, D=statsD)\n",
    "            outfile.write(CURR_INFO)\n",
    "            PLOT=\"\"\"<IMG SRC=\\\"{PLOTPATH}\\\" WIDTH=100%><br><br>\"\"\"\n",
    "            CURR_PLOT = PLOT.format(PLOTPATH=plotz)\n",
    "            outfile.write(CURR_PLOT)\n",
    "            print(\">>>>>>>>>--------> COPYING OUTPUT TO HTML\")\n",
    "            print(\">>>>>>>>>--------> ADDING PLOT TO HTML\")\n",
    "                ## ADD FILE FOR GOOD SUBJECT \n",
    "        # --sometimes you have a great subject who didn't move\n",
    "            if os.path.isfile(\"%s/%s_confound.txt\"%(motion_assessment_path, file))==False:\n",
    "                os.system(\"touch %s/%s_confound.txt\"%(motion_assessment_path, file))\n",
    "        ## CHECK FOR BAD SUBJECTS: ABOVE OUR THRESHOLD\n",
    "        # how many columns are there = how many 'bad' points\n",
    "            check = subprocess.check_output(\"grep -o 1 %s/%s_confound.txt | wc -l\"%(motion_assessment_path, file), shell=True)\n",
    "            num_scrub = [int(s) for s in check.split() if s.isdigit()]\n",
    "            print(\"NUM SCRUB: \", str(num_scrub[0]), \"\\n\")\n",
    "            if num_scrub[0] > comparator: #if the number in check is greater than num_scrub then we don't want it\n",
    "                with open(out_bad_bold_list, \"a\") as myfile: #making a file that lists all the bad ones\n",
    "                    myfile.write(\"%s/%s\\n\"%(derivatives_dir, file))\n",
    "                    print(\"wrote bad file\")\n",
    "                myfile.close()\n",
    "    except FileNotFoundError:   \n",
    "        print(\"FILE IS EMPTY, PASSING\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global input_dir\n",
    "    global derivatives_dir\n",
    "    global subjects\n",
    "    subjects = []\n",
    "    set_parser()\n",
    "    base_path = arglist[\"BASEDIR\"]\n",
    "    input_dir = os.path.join(base_path, 'fmriprep' )\n",
    "    derivatives_dir = os.path.join(base_path, 'derivatives')\n",
    "    output_files()\n",
    "    get_subjects()\n",
    "        \n",
    "    for sub in sorted(subjects):\n",
    "        set_paths(sub)\n",
    "        if args.STRIP == True:\n",
    "            skull_strip(sub)\n",
    "        if args.MOCO == True:\n",
    "            fd_check(sub)\n",
    "\n",
    "# Start Program\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
