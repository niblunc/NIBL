{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(sub):\n",
    "    check_dict[sub] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-92161c14d2aa>, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-92161c14d2aa>\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    current_files = [x for x in rest_files if len(rest_files) != 3]\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, glob\n",
    "import pandas as pd \n",
    "\n",
    "#BIDS_PATH = \n",
    "#MULTI_SESS =\n",
    "\n",
    "#def check_subjects():\n",
    "## Set input path for BIDS data and get subjects \n",
    "SUBJ_DIRS = glob.glob(os.path.join(\"/projects/niblab/bids_projects/Experiments/Bevel/BIDS\", \"sub-*\"))\n",
    "check_dict = {} ## initialize dictionary\n",
    "TOTAL_ERRORS = 0 \n",
    "error_dict = {}\n",
    "\n",
    "## iterate through subjects and inspect their files and \n",
    "for SUBDIR in sorted(SUBJ_DIRS):\n",
    "    sub_id = SUBDIR.split(\"/\")[-1] # get subject id\n",
    "    # MAKE DICTIONARY \n",
    "    check_dict[sub_id] = {} # add subject id to dictionary\n",
    "    # GET RELEVANT PATHS, AND FILES \n",
    "    ## --here we set the data directory paths we want to check : (func/, anat/, and fmap/)\n",
    "    ## and then we grab all the *nii.gz files within them\n",
    "    prob_files = glob.glob(os.path.join(SUBDIR, 'func', '*task-prob*'))\n",
    "    rest_files = glob.glob(os.path.join(SUBDIR, 'func', '*task-rest*'))\n",
    "    anat_files = glob.glob(os.path.join(SUBDIR, 'anat', '*T1w*'))\n",
    "    magn_files = glob.glob(os.path.join(SUBDIR, 'fmap', '*magnitude*'))\n",
    "    phase_files = glob.glob(os.path.join(SUBDIR, 'fmap', '*phasediff*'))\n",
    "    \n",
    "    def set_error(index, key, sub_id):\n",
    "        if index == 0:\n",
    "            error_dict[sub_id].update({\"%s_TSV\"%key : \"File Not Found\"})\n",
    "        elif index == 1:\n",
    "            error_dict[sub_id].update({\"%_JSON\"%key : \"File Not Found\"})\n",
    "        else:\n",
    "            error_dict[sub_id].upate({\"%s_NIFTI\"%key : \"File Not Found\"})\n",
    "\n",
    "            \n",
    "    ###############################################################\n",
    "    # Check fmap/ files\n",
    "    # I. Magnitude file check-\n",
    "    error_files = [x for x in rest_files if len(phase_files) != 2]\n",
    "    if not error_files:\n",
    "        pass\n",
    "    else:\n",
    "        for file in error_files:\n",
    "            if \".json\" in file:\n",
    "                json_check = True\n",
    "            elif \".tsv\" in file:\n",
    "                tsv_check = True \n",
    "            else:\n",
    "                nifti_check = True \n",
    "        t = [tsv_check, json_check, nifti_check]\n",
    "        for index, bool_ in enumerate(t):\n",
    "            key = \"PHASE\"\n",
    "            if bool_ == False: #FOUND ERROR !!!!\n",
    "                if sub_id not in error_dict:\n",
    "                    error_dict[sub_id] = {}\n",
    "                set_error(index,key, sub_id)\n",
    "    # II. Magnitude file check-\n",
    "    error_files = [x for x in rest_files if len(magn_files) != 4]\n",
    "    if not error_files:\n",
    "        pass\n",
    "    else:\n",
    "        for file in error_files:\n",
    "            if \".json\" in file:\n",
    "                json_check = True\n",
    "            elif \".tsv\" in file:\n",
    "                tsv_check = True \n",
    "            else:\n",
    "                nifti_check = True \n",
    "        t = [tsv_check, json_check, nifti_check]\n",
    "        for index, bool_ in enumerate(t):\n",
    "            key = \"MAG\"\n",
    "            if bool_ == False: #FOUND ERROR !!!!\n",
    "                if sub_id not in error_dict:\n",
    "                    error_dict[sub_id] = {}\n",
    "                set_error(index,key, sub_id)\n",
    "    \n",
    "    ###############################################################\n",
    "    # Check anat/ files\n",
    "    error_files = [x for x in rest_files if len(anat_files) != 2]\n",
    "    if not error_files:\n",
    "        pass\n",
    "    else:\n",
    "        for file in error_files:\n",
    "            if \".json\" in file:\n",
    "                json_check = True\n",
    "            elif \".tsv\" in file:\n",
    "                tsv_check = True \n",
    "            else:\n",
    "                nifti_check = True \n",
    "        t = [tsv_check, json_check, nifti_check]\n",
    "        for index, bool_ in enumerate(t):\n",
    "            key = \"ANAT\"\n",
    "            if bool_ == False: #FOUND ERROR !!!!\n",
    "                if sub_id not in error_dict:\n",
    "                    error_dict[sub_id] = {}\n",
    "                set_error(index,key, sub_id)\n",
    "  \n",
    "    ###############################################################\n",
    "    # I. Check to for \"rest\" files\n",
    "    current_files = [x for x in rest_files if len(rest_files) != 3]\n",
    "    if not current_files:\n",
    "        pass \n",
    "    else:\n",
    "        #initialize local parameters\n",
    "        tsv_check = False\n",
    "        json_check = False\n",
    "        nifti_check = False\n",
    "        for file in current_files:\n",
    "            if \".json\" in file:\n",
    "                json_check = True\n",
    "            elif \".tsv\" in file:\n",
    "                tsv_check = True \n",
    "            else:\n",
    "                nifti_check = True \n",
    "        t = [tsv_check, json_check, nifti_check]\n",
    "        for index, bool_ in enumerate(t):\n",
    "            key = \"REST\"\n",
    "            if bool_ == False: #FOUND ERROR !!!!\n",
    "                if sub_id not in error_dict:\n",
    "                    error_dict[sub_id] = {}\n",
    "                set_error(index,key, sub_id)\n",
    "\n",
    "    ###############################################################\n",
    "    # II. Check \"task-prob\" files\n",
    "    if not prob_files: # FOUND ERROR !!!! \n",
    "        if sub_id not in error_dict:\n",
    "                    error_dict[sub_id] = {}\n",
    "        ERROR = \"NO functional files found\"\n",
    "    else:\n",
    "        # for each run expect to have total of 3 files - *bold.json, *bold.nii.gz, *events.tsv\n",
    "        run1_files = glob.glob(os.path.join(SUBDIR, \"func\", \"*run-1*\"))\n",
    "        run2_files = glob.glob(os.path.join(SUBDIR, \"func\", \"*run-2*\"))\n",
    "        run3_files = glob.glob(os.path.join(SUBDIR, \"func\", \"*run-3*\"))\n",
    "        run4_files = glob.glob(os.path.join(SUBDIR, \"func\", \"*run-4*\"))\n",
    "        runs = [run1_files, run2_files, run3_files, run4_files]\n",
    "        keywordlist = [\".tsv\", \".json\", \"nii.gz\"]\n",
    "        run_lists = [run1_files, run2_files, run3_files, run4_files]\n",
    "        target = 0\n",
    "        for run in run_lists:\n",
    "            #initialize local parameters\n",
    "            tsv_check = False\n",
    "            json_check = False\n",
    "            nifti_check = False\n",
    "            for file in run:\n",
    "                for keyword in keywordlist:\n",
    "                    if keyword in file:\n",
    "                        #print(\"PASSED %s\"%keyword)\n",
    "                        if keyword == \".tsv\":\n",
    "                            tsv_check = True \n",
    "                        elif keyword == \".json\":\n",
    "                            json_check = True \n",
    "                        else:\n",
    "                            nifti_check = True\n",
    "            checklist=[tsv_check, json_check, nifti_check]\n",
    "            if (tsv_check and json_check and nifti_check) == True:\n",
    "                pass\n",
    "            else: # FOUND ERROR !!!! \n",
    "                #for value in checklist:\n",
    "                 #   if value == False:\n",
    "                  #      print(value.index())\n",
    "                bad_files = [i for i, e in enumerate(checklist) if e == False]\n",
    "                if sub_id not in error_dict:\n",
    "                    error_dict[sub_id] = {}\n",
    "                for index in bad_files:\n",
    "                    set_error(index, \"FUNC\", sub_id)\n",
    "                    \n",
    "        #######WRITE TO FILE -- QUALITY ANALYSIS REPORTING\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    else: # IDENTIFY FUNCS\n",
    "        train_run_count=0\n",
    "        rl_count = 0 \n",
    "        # Expecting 4 BEVEL functionals \n",
    "        for func_ in sorted(FUNCS):\n",
    "            name = func_.split(\"/\")[-1] \n",
    "            TASK = name.split(\"_\")[1]\n",
    "            print(name)\n",
    "            if \"rest\" in name:\n",
    "                resting_file = name\n",
    "                rest_check = \"PASS\"\n",
    "                check_dict[SUBJECT][\"REST_CHECK\"] = rest_check \n",
    "            else:\n",
    "                if \"prob\" in TASK:\n",
    "                    if \"run\" in name:\n",
    "                        TRAIN_RUN = name.split(\"_\")[2]\n",
    "                        train_run_count = train_run_count + 1\n",
    "        if train_run_count == 4:\n",
    "            func_check = \"PASS\"\n",
    "        else:\n",
    "            func_check = \"FAIL\"\n",
    "    check_dict[SUBJECT][\"TRAIN_COUNT\"] = train_run_count\n",
    "    check_dict[SUBJECT][\"FUNC_TRAIN_CHECK\"] = func_check\n",
    "    \n",
    "            #rint(\"RUN COUNT: \", run_count)\n",
    "    # IDENTIFY ANATS AND ANY ERRORS\n",
    "    if not ANATS:\n",
    "        anat_check = \"FAIL\"\n",
    "        #print(\"********ERROR! NO ANATOMICALS: \", SUBJECT)\n",
    "        #######WRITE TO FILE -- QUALITY ANALYSIS REPORTING\n",
    "    else:\n",
    "        anat_file = str(ANATS)\n",
    "        anat_check = \"PASS\"\n",
    "    check_dict[SUBJECT][\"ANAT_CHECK\"] = anat_check\n",
    "    # IDENTIFY FMAPS AND ANY ERRORS\n",
    "    ## here I am initializing the check variables\n",
    "    phase_check = \"FAIL\"\n",
    "    mag1_check = \"FAIL\"\n",
    "    mag2_check = \"FAIL\"\n",
    "    if not FMAPS:\n",
    "        print(\"********ERROR! NO FMAPS: \", SUBJECT)\n",
    "        fmap_check = \"FAIL\"\n",
    "    else:\n",
    "        for file in FMAPS:\n",
    "            name = file.split(\"/\")[-1]\n",
    "            IDENTIFIER = name.split(\"_\")[1]\n",
    "            if \"phasediff\" in IDENTIFIER:\n",
    "                phase_check = \"PASS\"\n",
    "                phase_file = file\n",
    "            if \"magnitude1\" in IDENTIFIER:\n",
    "                mag1_check = \"PASS\"\n",
    "                mag1_file = file\n",
    "            if \"magnitude2\" in IDENTIFIER: \n",
    "                mag2_check = \"PASS\"\n",
    "                mag2_file = file\n",
    "        #print(phase_check, mag1_check, mag2_check)\n",
    "        if phase_check and mag1_check and mag2_check == \"PASS\":\n",
    "            fmap_check = \"PASS\"\n",
    "        elif phase_check and mag1_check and mag2_check != \"PASS\":\n",
    "            fmap_check = \"FAIL\"\n",
    "        else:\n",
    "            fmap_check = \"FAIL\"\n",
    "    check_dict[SUBJECT][\"FMAP_CHECK\"] = fmap_check\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = pd.DataFrame.from_dict(check_dict, orient='index')\n",
    "\n",
    "TOTAL_ERRORS = 0 \n",
    "error_dict = {}\n",
    "#for index, row in df.iterrows():\n",
    " #   print(row)\n",
    "    \n",
    "for index, row in df.iterrows():\n",
    "    # initialize local parameters \n",
    "    REST_ER = False\n",
    "    FUNC_ER = False\n",
    "    ANAT_ER = False\n",
    "    FMAP_ER = False\n",
    "    if row[\"REST_CHECK\"] == \"FAIL\":\n",
    "        ERROR = True\n",
    "        REST_ER = \"REST\"\n",
    "        string=\"FAILED resting file check\"\n",
    "        print(string)\n",
    "    if row[\"FUNC_TRAIN_CHECK\"] == \"FAIL\":\n",
    "        ERROR = True \n",
    "        FUNC_ER = \"FUNC\"\n",
    "    if row[\"ANAT_CHECK\"] == \"FAIL\":\n",
    "        ERROR = True \n",
    "        ANAT_ER = \"ANAT\"\n",
    "    if row[\"FMAP_CHECK\"] == \"FAIL\":\n",
    "        ERROR = True\n",
    "        FMAP_ER = \"FMAP\"\n",
    "    else:\n",
    "        ERROR = False    \n",
    "    # check if there was an error counted and add to dictionary if so\n",
    "    if ERROR == True:\n",
    "        TOTAL_ERRORS = TOTAL_ERRORS + 1\n",
    "        #create dictionary value for error-fill in with values\n",
    "        if index not in error_dict:\n",
    "            error_dict[index] = {}\n",
    "        for value in [FMAP_ER, ANAT_ER, FUNC_ER, REST_ER]:\n",
    "            if value != False:\n",
    "                print(value)\n",
    "                error_dict[index] = { value: }\n",
    "        print(\"Analysis for subject....%s\\n\"%index)\n",
    "        print(\"_________________________________\")\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "print(\"Total Subject Count: %s\"%len(SUB_DIRS))\n",
    "print(\"Total Errors: %s\"%TOTAL_ERRORS)\n",
    "        \n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
